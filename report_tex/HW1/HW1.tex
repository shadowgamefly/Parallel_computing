\def\hnumber{1}
\def\student{Jerry Sun}
\def\studentid{ys7va}

\documentclass{cs4444}

\begin{document}

\maketitle

\section{Problem Description}
The goal of this assignment is to optimize a computationally complicated algorithm for a serial processor using several different optimization strategies that were mentioned in class, and to compare their performance along with different optimization flags(-O) for gcc. The main equation is 
	
	\[E = \sum_{j<i, r_{ij} <= cut}\frac{e^{r_{ij} * q_i}*e^{r_{ij}*q_j}}{r_{ij}} - 1/a\] 

\section{Approach}
Several different strategies were applied during testing including (The effect of each modification will be further explained in Section Analysis): 

\begin{itemize}
	\item Reduce expensive operations:

		Square root and exponentiation are usually very expensive and time consuming, so we want to minimize those kinds of operations as much as possible.
		
	\item Avoid repetitive operations in loop header or memory lookup:
	 
		Typically we want to minimize the unnecessarily repetitive process within the for loop, like function calls and other minor operations. 
 
	\item Avoid branch prediction causing by if and loop:
		
		Loop and if statement cause a lot of branch mispredictions, and thus causing stall and swipe based on different assembly languages, so we  want to minimize the possible for loop and if statement.
	
	\item Avoid memory(array) lookup:
		
		The program usually read memory in a block size. Especially in multidimensional array, we want to minimize the array lookup or at least put the lookup process into linear. 
	
\end{itemize}

\newpage

\section{Results}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| }
\hline
 \multicolumn{5}{|c|}{Optimization Strategies} & \multicolumn{2}{|c|} {Result(s)}
  \\
 \hline
 Flags & Expansive Operation & Repetitive call & Branch Prediction & Memory Lookup & Calculation & Total\\ 
 \hline
 N/A & &  &  &  & 25.9121 & 25.9297\\  
 \hline
 -O1 & &  &  &  & 3.3636 & 3.3758\\  
 \hline
 -O2 & &  &  &  & 3.3180 & 3.3314\\  
 \hline
 -O3 & & & & & 3.2800 & 3.2947 \\
 \hline
 N/A & \checkmark &  &  &  & 6.0292 & 6.0436\\
 \hline
 N/A & & \checkmark &  &  & 25.4549 & 25.4681\\
 \hline
 N/A & &  & \checkmark  &  & 25.2274 & 25.2415\\
 \hline
 N/A & &  &  & \checkmark  & 25.3950 & 25.4092\\
 \hline
 -O3 & \checkmark & \checkmark & \checkmark & \checkmark & 5.2601 & 5.2744\\  
 \hline
 -O3 & \checkmark &  & \checkmark & & 5.2451 & 5.2573\\  
 \hline

  -O3 & \checkmark &  &  &  & 2.3043 & 2.3172\\  
 \hline
  -O3 & & \checkmark  &  &  & 3.2490 & 3.2621\\  
 \hline
  -O3 & & &\checkmark &  & 3.0640 & 3.0774\\  
 \hline
 -O3 & & & & \checkmark & 3.2504 & 3.2636\\  
 \hline
 -O3 & \checkmark & \checkmark & \checkmark & \checkmark & 1.9922 & 2.0056\\  
 \hline
 -O3 & \checkmark &  & \checkmark & & 1.9888 & 2.0003\\  
 \hline

 
\end{tabular}
\end{center}
\footnotesize{$^1$ Given the space of the report, only those representative results are shown in the table.}\\
\footnotesize{$^2$ The metadata of the test can be found in the Section 4 Analysis.}\\
\footnotesize{$^3$ The test result was the average of 10 runs for each version}\\

\normalsize
\section{Analysis}
In this section, first we will introduce the metadata of this project and then we will further explore each single optimization strategies applied whether it worked or not.

\subsection{Metadata}
The result above was tested under 2.4GHZ Intel Core i5(single processor, two cores). The size of the corresponding caches are L2 Cache (per Core):256 KB, L3 Cache:3 MB, Memory:8 GB. The version of the compiler is llvm 7.3.0/gcc 4.2.1. Further, all the input is generated by a size of 20000 within a random seed 1, and take a cut off at 0.5.

\subsection{Expansive Operations}
According to the result graph, we can find it is the most effective optimization applied except the -O flags. In particular, after some experiment we find out there are three changed spots that are useful. 
	 \begin{lstlisting}[language=C]]
	 	// Remove all the pow function use simple multiplication
	 	vec2 = (coords[0][i]-coords[0][j]) * (coords[0][i]-coords[0][j])
                 + (coords[1][i]-coords[1][j]) * (coords[1][i]-coords[1][j])
                 + (coords[2][i]-coords[2][j]) * (coords[2][i]-coords[2][j]);
 
	 \end{lstlisting}
	 
	 \begin{lstlisting}[language=C] 
		rij = vec2; //remove the original sqrt function
       			    // Check if this is below the cut off
        if ( rij <= cut_new ) { //take cut_new = cut^2 before the whole computation process
        rij = sqrt(rij);    //apply sqrt only necessary
            continue with rij..
            }
	 \end{lstlisting}
	 
	 \begin{lstlisting}[language=C] 
	 	current_e = (exp(rij*q[i-1] + rij*q[j-1]))/rij; //combine two exp function into one  
	 	
	 \end{lstlisting}
	 
	 There are two major reasons that they can offer so much speed-up in the whole process. First, we greatly reduce the amount of complex computation within the program, and secondly both of those two changes are also function calls, which result into unnecessary assembly lines as well as branch misprediction within the for loop. As we can see in the real code there are several other minor update within the operation side but none of the others has been more effective than the three above. 
	 \newline
	 However, there are some problem within this method as well. In general, within float operations as it is not so sensitive within large numbers. By using the second modification, we find that the precision has changed, as both sides of the comparison has became smaller, leading to a minor loss in final result, but the detraction can be controlled within 1e-6 which we assume can be neglected.
	 
\subsection{Unnecessary operations in for loop and array} 
	Usually we want to make the header of the for loop as simple as possible, so that there will be no more unnecessary additional function and operations being called during the execution. There is only one such place here.
	 \begin{lstlisting}[language=C] 
		for (i=0; i<natom; ++i) {  		// change from 1 -> natom to 0 -> natom - 1
        for (j=0; j < i; ++j) { 	    //similar as above 
	 	/* vec2 = pow((coords[0][i-1]-coords[0][j-1]),2.0)
                       + pow((coords[1][i-1]-coords[1][j-1]),2.0)
                       + pow((coords[2][i-1]-coords[2][j-1]),2.0);*/
        //We changed it into by reducing one in the start and end point within the for loop
        vec2 = pow((coords[0][i]-coords[0][j]),2.0)
                       + pow((coords[1][i]-coords[1][j]),2.0)
                       + pow((coords[2][i]-coords[2][j]),2.0)
                       
        ...
        
        //Compute with q[i] instead of q[i-1]     
            
	 \end{lstlisting}

	However, this turns out to be not so effective. We believe the key reason is that within the amount of calculation within a single for loop. The operation inside the array might only cost one single assembly line instead of making some function call or complex calculation which can usually 	give much better performance boost.

\subsection{Number of for loops and if statement}
	if statements are usually very expensive because of the branch misproduction and its consequences, so we want to minimize such operation as much as possible. It turns out to be rather effective during the experiment. 
		\begin{lstlisting}[language=C] 
		
	 	for (i=1; i<=natom; ++i) {
        for (j = 1; j < i; ++j) {			//for (j=1; j<=natom; ++j) {
            Execute	}}}						//if ( j < i ) {   
            
            
	 \end{lstlisting}
	 
	 By doing this we can actually reduce half of the inner for loop and half of the unnecessary if statement. However, this method also doesn't turn out to work so well as usual. This is mainly because, while we are able to reduce so much branch misprediction, the inner loops cutoff can't give much because those are originally ineffective iteration, as there is no real calculation taking place in those reduced for loops. 
		
\subsection{memory lookup} 
	Each layers of memory read data in blocks, so we always want to turn the array lookup into a linear way so that we can maximize cache hit and reduce low-effectiveness memory read. Also we want to minimize some repetitive memory lookup.
	 \begin{lstlisting}[language=C] 
		double i1 = coords[0][i];
      	double i2 = coords[1][i];
      	double i3 = coords[2][i];
	 	/* for loops, etc. */
	 	vec2 = pow(i1-coords[0][j-1]),2.0)
                       + pow(i2-coords[1][j-1]),2.0)
                       + pow(i3-coords[2][j-1]),2.0)
	 \end{lstlisting}
	 
	 By doing this, in each iteration for i, we only need to access three value of i only once. However, it also doesn't work out well. Of course, we can change the arrangement of the arrays, making it like natom * 3, so that the read of coords[i][0,1,2] would now be in linear, instead of jumping around. However, this doesn't work out and even resulted into negative effect, taking longer time in execution. 
	 
	   
\section{Conclusion}
	The Analysis above gave us some idea about some instincts in strategies for computationally heavy problems. The main focus for such optimization shall always lay in major operations, for instance, the exponential operation and pow functions in this particular problem. The effectiveness of the optimization is closely connected with the effort to improve the performance of the computation itself and reduce unnecessary computations. Other from that, assume the algorithm isn't very poorly designed, those other optimizations might not be able to achieve the effect of the above two.

\section{Curious}
	During the whole assignment, there is one thing in particular makes me curious, that is the failure of the optimization of memory lookup. Based on my understanding of how cache and memory work, if I changed the structure of the whole array from 3*n to n*3, the memory read should be pretty effective(almost no memory will be swiped out without usage). However, it turns out to have zero or even negative effect, which I can't explain. I tried to look up online for related explanation but also didn't get anything useful.

\section{Pledge}

\pledge
\newpage
\section{Appendix}

\lstinputlisting[language=c]{final2.c}

\end{document}
